{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8e689d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T20:07:46.654477Z",
     "start_time": "2021-03-04T20:07:46.629002Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision prometheus_client --progress-bar off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f832a27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T20:08:02.078254Z",
     "start_time": "2021-03-04T20:08:02.051448Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from prometheus_client import CollectorRegistry, Gauge, push_to_gateway\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "                                ])\n",
    "\n",
    "trainset = datasets.MNIST('dataset/train',\n",
    "                          download=True, train=True, transform=transform)\n",
    "valset = datasets.MNIST('dataset/test',\n",
    "                        download=True, train=False, transform=transform)\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=128, shuffle=True)\n",
    "val_dl = torch.utils.data.DataLoader(valset, batch_size=128, shuffle=True)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(2, 2)),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(in_features=5408, out_features=128),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(in_features=128, out_features=10),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "print(model)\n",
    "\n",
    "\n",
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)\n",
    "\n",
    "\n",
    "def fit(epochs, model, loss_func, opt, train_dl, val_dl):\n",
    "    current_time = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        step_counter = []\n",
    "        time_pre_loop = time.perf_counter()\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            time_pre_step = time.perf_counter()\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "            time_post_step = time.perf_counter()\n",
    "            step_counter.append(time_post_step - time_pre_step)\n",
    "        time_post_loop = time.perf_counter()\n",
    "        step_time_avg = sum(step_counter) / len(step_counter)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in val_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "\n",
    "        print(\"Epoch: {epoch}. Epoch Time {time:0.2f}s,\"\n",
    "              \" Step Time: {step:0.2f}ms Validation Loss: {val_loss}\"\n",
    "              .format(epoch=epoch, time=time_post_loop - time_pre_loop,\n",
    "                      step=step_time_avg * 1000, val_loss=val_loss))\n",
    "\n",
    "        value_formatter = \"{0:.2f}\"\n",
    "        add_metrics_data(current_time, epoch, value_formatter.format(time_post_loop - time_pre_loop),value_formatter.format(step_time_avg * 1000))\n",
    "\n",
    "\n",
    "pushgateway_url = \"http://prom-push-as-pushgateway.apps.zero.massopen.cloud\"\n",
    "registry = CollectorRegistry()\n",
    "epoch_gauge = Gauge(name='epoch_duration_seconds', documentation='epoch_value is the metric itself, the stuff in the {}s are tags',labelnames=[\"model\",\"framework\",\"date\",\"epoch\"],registry=registry)\n",
    "step_gauge = Gauge(name='step_during_milliseconds', documentation='step_during_milliseconds is the metric itself, the stuff in the {}s are tags',labelnames=[\"model\",\"framework\",\"date\",\"epoch\"],registry=registry)\n",
    "\n",
    "def add_metrics_data(current_time, epoch_num, epoch_value, step_value):                  \n",
    "    epoch_gauge.labels(\"mnist-minimal\",\"Pytorch\",current_time,epoch_num).set(epoch_value)\n",
    "    step_gauge.labels(\"mnist-minimal\",\"Pytorch\",current_time,epoch_num).set(step_value)  \n",
    "    push_to_gateway(pushgateway_url, job='jupyterhub_load', registry=registry)\n",
    "\n",
    "\n",
    "fit(epochs=5, model=model, loss_func=F.cross_entropy,\n",
    "    opt=optim.Adam(model.parameters()), train_dl=train_dl, val_dl=val_dl)\n"
   ]
  }
 ],
 "metadata": {
  "finalized": {
   "timestamp": 1614876067216,
   "trusted": false
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
